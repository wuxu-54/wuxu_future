# MCP

MCP（Model Context Protocol，模型上下文协议）是Anthropic公司于2024年11月推出的一种开放标准协议，旨在为大型语言模型（LLM）与外部数据源、工具和服务之间的交互提供统一的通信框架。其核心目标是通过标准化接口解决数据孤岛问题，增强AI模型的实时数据访问能力和任务执行灵活性。

## 前言

资料：

```txt
https://mp.weixin.qq.com/s/TYoJ9mQL8tgT7HjTQiSdlw
```

个人理解：mcp不同于函数调用，开发端需要两个：1. 前端（ 客户端/web网页） 2. 服务端

猜测原因：mcp是一种通用协议，类似电脑的转换器，所以需要 【前端+服务端】两个端统一处理

## 一、核心价值与定义

1. **打破数据孤岛**  
   MCP通过统一协议连接AI模型与本地或远程资源（如数据库、API、文件系统等），使得模型能够动态获取实时信息，而非局限于训练时的静态数据。例如，AI助手可通过MCP直接读取本地Excel表格或调用GitHub API，无需手动复制粘贴数据。
2. **简化开发流程**  
   传统开发中，每个数据源与AI模型的集成需定制化代码，而MCP通过标准化协议减少重复开发。开发者只需遵循协议规范，即可快速接入多种数据源，类似“USB-C接口”实现即插即用。

## 二、技术架构

MCP采用客户端-服务器架构，包含以下核心组件：  

1. **MCP客户端（Client）**：嵌入在AI应用（如Claude Desktop、Cursor IDE）中，负责向服务器发送请求并处理响应。客户端会先获取服务器提供的工具列表，结合用户查询调用LLM决策是否需要使用工具。
2. **MCP服务器（Server）**：独立运行的程序，提供资源（如文件内容）、工具（如API调用）和提示模板。例如，一个GitHub MCP服务器可封装仓库管理功能，供AI模型调用。
3. **通信机制**：支持本地（通过标准输入输出）和远程（基于SSE/HTTP）两种方式，消息格式遵循JSON-RPC 2.0标准，确保跨平台兼容性。

## 三、与Function Calling的区别

- **Function Calling**：是LLM调用预定义函数的机制，但高度依赖特定平台（如OpenAI），不同模型间的实现差异大。
- **MCP**：作为通用协议，独立于具体模型，支持多模型（如Claude、DeepSeek）接入，并提供更广泛的生态工具库（如社区贡献的MCP服务器），实现“一次集成，处处运行”。

## 四、安全性设计

MCP通过以下机制保障数据安全：  

1. **权限控制**：服务器可配置访问规则，仅响应已验证请求。  
2. **加密传输**：支持多种加密算法保护通信过程。  
3. **敏感信息隔离**：API密钥等敏感数据由服务器管理，避免泄露给LLM提供商。

## 五、典型应用场景

1. **开发工具集成**：AI编程助手通过MCP读取Git仓库、调试代码或调用Sentry分析问题。  
2. **生产力工具**：自动整理会议记录（结合Slack和本地文件系统）或生成数据分析报告（连接数据库）。  
3. **浏览器自动化**：通过Puppeteer MCP服务器实现网页抓取或自动化测试。

## 六、未来展望

MCP的开放生态正在快速发展，社区已推出多种预置服务器（如Apifox MCP Server支持API文档生成代码）。随着更多工具加入，AI将更深度融入工作流，例如直接修改在线文档或管理云资源（AWS/Azure）。

如需进一步了解具体配置或实战案例，可参考[Cline配置指南](citation:4)或[Apifox MCP Server应用场景](citation:7)。

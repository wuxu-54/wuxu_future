# 文件快速解析

在 Groovy 中快速解析文件数据的关键在于利用其**简洁语法**和**内置工具**（如闭包、集合操作和第三方库）。以下是针对不同场景的快速解析方案：

---

## **1. 结构化文本文件（如 CSV）**

### 使用 `split` 快速切割

```groovy
def csvData = new File("data.csv").readLines().collect { line ->
    line.split(',') // 按逗号分割
}
csvData.each { println "字段: $it" }
```

### 使用 `csv-records` 库（推荐）

```groovy
@Grab('com.xlson.groovycsv:groovycsv:1.5')
import static com.xlson.groovycsv.CsvParser.parseCsv

def csvText = new File("data.csv").text
def data = parseCsv(csvText)
data.each { record ->
    println "Name: ${record.name}, Age: ${record.age}"
}
```

---

## **2. JSON 文件**

### 内置 `JsonSlurper`（无需额外依赖）

```groovy
import groovy.json.JsonSlurper

def jsonFile = new File("data.json")
def data = new JsonSlurper().parse(jsonFile)
println "用户数量: ${data.users.size()}"
```

### 处理大型 JSON（流式解析）

```groovy
@Grab('org.glassfish:jakarta.json:2.0.1')
import jakarta.json.Json
import jakarta.json.stream.JsonParser

def jsonParser = Json.createParser(new FileReader("bigdata.json"))
while (jsonParser.hasNext()) {
    def event = jsonParser.next()
    if (event == JsonParser.Event.KEY_NAME && jsonParser.getString() == "key") {
        jsonParser.next()
        println "Value: ${jsonParser.getString()}"
    }
}
jsonParser.close()
```

---

## **3. XML 文件**

### 使用 `XmlSlurper`（惰性加载，适合大文件）

```groovy
def xml = new File("data.xml").newInputStream()
def data = new XmlSlurper().parse(xml)
data.books.book.each { book ->
    println "书名: ${book.title.text()}, 价格: ${book.price.text()}"
}
```

---

## **4. 固定格式日志文件**

### 正则提取（示例解析 Nginx 日志）

```groovy
def pattern = ~/(?<ip>\d+\.\d+\.\d+\.\d+) - - \[(?<time>.+?)\] "(?<method>\w+) (?<url>.+?) HTTP\/\d\.\d" (?<status>\d+) (?<size>\d+)/

new File("access.log").eachLine { line ->
    def matcher = pattern.matcher(line)
    if (matcher.matches()) {
        println "IP: ${matcher.group('ip')}, 状态码: ${matcher.group('status')}"
    }
}
```

---

## **5. 高效处理大文件**

### 流式逐行处理（避免内存溢出）

```groovy
new File("huge.txt").withReader { reader ->
    while ((line = reader.readLine()) != null) {
        // 实时处理每一行
        processLine(line)
    }
}
```

---

## **6. 数据库导入（快速批处理）**

### 结合 SQL 批量插入

```groovy
@Grab('org.apache.commons:commons-dbcp2:2.9.0')
import groovy.sql.Sql

def sql = Sql.newInstance("jdbc:mysql://localhost/test", "user", "pass", "com.mysql.cj.jdbc.Driver")
def batchSize = 1000

new File("data.csv").eachLine(1, { line, lineNo ->
    if (lineNo > 1) { // 跳过标题行
        def parts = line.split(',')
        sql.executeInsert("INSERT INTO table VALUES (?, ?)", [parts[0], parts[1]])
        if (lineNo % batchSize == 0) sql.commit() // 批量提交
    }
})
sql.close()
```

---

## **性能优化技巧**

1. **惰性处理**：用 `eachLine` 替代 `readLines()` 处理大文件
2. **并行处理**（适合多核 CPU）：

   ```groovy
   def lines = new File("data.txt").readLines()
   lines.parallelStream().forEach { process(it) }
   ```

3. **内存映射文件**（超大型文件）：

   ```groovy
   def channel = new RandomAccessFile("huge.bin", "r").channel
   def buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size())
   ```

---

## **总结**

Groovy 解析数据的核心优势：

- **简洁语法**：`eachLine` + 闭包组合
- **内置解析器**：`XmlSlurper`/`JsonSlurper` 开箱即用
- **无缝 Java 生态**：可结合 Jackson、OpenCSV 等高性能库
- **灵活扩展**：通过 Metaprogramming 添加自定义解析逻辑

根据数据格式和规模选择最合适的方案，通常优先使用 Groovy 内置方法，遇到复杂场景再引入专业库。
